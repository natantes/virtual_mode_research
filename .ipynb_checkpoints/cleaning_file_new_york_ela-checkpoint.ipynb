{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369252bf",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff7014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pyodbc\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad57591",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ab72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years for each dataframe\n",
    "years = [2019, 2021, 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c2a79",
   "metadata": {},
   "source": [
    "# Intialize Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e58529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_convert(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except ValueError:\n",
    "        print(f\"Value {val} can't be converted to int\")\n",
    "        return None\n",
    "    \n",
    "def import_mdb(MDBs, DRV, PWD, NAMES):\n",
    "    \n",
    "    databases = {}\n",
    "    \n",
    "    for MDB, NAME in zip(MDBs, NAMES):\n",
    "        # connect to db\n",
    "        con = pyodbc.connect('DRIVER={};DBQ={};PWD={}'.format(DRV,MDB,PWD))\n",
    "        cur = con.cursor()\n",
    "\n",
    "        # List all tables in the database\n",
    "        tables = list(map(lambda t: t.table_name, con.cursor().tables(tableType='TABLE')))\n",
    "\n",
    "        # Initialize an empty dictionary to hold your dataframes and databases\n",
    "        database = {}\n",
    "\n",
    "        # Try to read each table one by one\n",
    "        for table in tables:\n",
    "            try:\n",
    "                df = pd.read_sql(f'SELECT * FROM [{table}]', con)  # enclose table name in brackets\n",
    "                database[table] = df\n",
    "                print(f\"Successfully read table: {table}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read table: {table}\")\n",
    "                print(f\"Error: {e}\")\n",
    "        databases[NAME] = database\n",
    "        \n",
    "    return databases\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore', 'pandas only support SQLAlchemy connectable.*')\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b55ae7",
   "metadata": {},
   "source": [
    "# Import Enrollment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54b123b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read table: BEDS Day Enrollment\n",
      "Successfully read table: BOCES and N/RC\n",
      "Successfully read table: Demographic Factors\n",
      "Successfully read table: Institution Grouping\n",
      "Successfully read table: BEDS Day Enrollment\n",
      "Successfully read table: BOCES and N/RC\n",
      "Successfully read table: Demographic Factors\n",
      "Successfully read table: Institution Grouping\n",
      "Successfully read table: BEDS Day Enrollment\n",
      "Successfully read table: BOCES and N/RC\n",
      "Successfully read table: Demographic Factors\n",
      "Successfully read table: Institution Grouping\n"
     ]
    }
   ],
   "source": [
    "DRV = '{Microsoft Access Driver (*.mdb, *.accdb)}'\n",
    "PWD = 'pw'\n",
    "\n",
    "# Enroll Data Filepaths\n",
    "ENROLL_PATH = [\n",
    "               '../data/enrollment_2019/ENROLL2019.mdb;',\n",
    "               '../data/enrollment_2021/ENROLL2021.mdb;',\n",
    "               '../data/enrollment_2022/ENROLL2022.mdb;',\n",
    "              ]\n",
    "ENROLL_NAMES = [\n",
    "               'ENROLL2019',\n",
    "               'ENROLL2021',\n",
    "               'ENROLL2022',\n",
    "              ]\n",
    "\n",
    "\n",
    "enroll_data = import_mdb(ENROLL_PATH, DRV, PWD, ENROLL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c24ee0",
   "metadata": {},
   "source": [
    "# Import Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read table: ACC EM Chronic Absenteeism\n",
      "Successfully read table: ACC EM Combined Composite Growth\n",
      "Successfully read table: ACC EM Composite Performance\n",
      "Successfully read table: ACC EM ELP\n",
      "Successfully read table: ACC EM Growth\n",
      "Successfully read table: ACC EM Participation Rate\n",
      "Successfully read table: ACC EM Progress\n",
      "Successfully read table: ACC EM Recently Arrived ELLs\n",
      "Successfully read table: ACC HS CCCR\n",
      "Successfully read table: ACC HS Chronic Absenteeism\n",
      "Successfully read table: ACC HS Combined Composite Grad\n",
      "Successfully read table: ACC HS Composite Performance\n",
      "Successfully read table: ACC HS ELP\n",
      "Successfully read table: ACC HS Graduation Rate\n",
      "Successfully read table: ACC HS Participation Rate\n",
      "Successfully read table: ACC HS Progress\n",
      "Successfully read table: Accountability Levels\n",
      "Successfully read table: Accountability Status\n",
      "Successfully read table: Accountability Status by Subgroup\n",
      "Successfully read table: Annual EM ELA\n",
      "Successfully read table: Annual EM MATH\n",
      "Successfully read table: Annual EM SCIENCE\n",
      "Successfully read table: Annual NYSAA\n"
     ]
    }
   ],
   "source": [
    "# Main Data Filepaths\n",
    "MAIN_PATH = [\n",
    "               '../data/SRC2019/SRC2019.mdb;',\n",
    "               '../data/SRC2021/SRC2021.mdb;',\n",
    "               '../data/SRC2022/SRC2022.mdb;',\n",
    "              ]\n",
    "MAIN_NAMES = [\n",
    "               'MAIN2019',\n",
    "               'MAIN2021',\n",
    "               'MAIN2022',\n",
    "              ]\n",
    "\n",
    "main_data = import_mdb(MAIN_PATH, DRV, PWD, MAIN_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac07e7d",
   "metadata": {},
   "source": [
    "# Import Dropout Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886dc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data22 = pd.read_csv(\"./raw_data/GRAD_RATE_AND_OUTCOMES_2022.csv\", thousands=',')\n",
    "data21 = pd.read_csv(\"./raw_data/GRAD_RATE_AND_OUTCOMES_2021.csv\", thousands=',')\n",
    "data19 = pd.read_csv(\"./raw_data/GRAD_RATE_AND_OUTCOMES_2019.csv\", thousands=',')\n",
    "\n",
    "dropout_dfs = [data19, data21, data22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf9734",
   "metadata": {},
   "source": [
    "# Combine Dropout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove districts, only keep schools\n",
    "for i, df in enumerate(dropout_dfs):\n",
    "    dropout_dfs[i] = df[df['aggregation_type'] == 'School']\n",
    "\n",
    "#   Only keep schools which are present in all years    #\n",
    "#########################################################\n",
    "\n",
    "# Convert the 'ID' column of each DataFrame to a set\n",
    "set1 = set(dropout_dfs[0]['aggregation_code'])\n",
    "set2 = set(dropout_dfs[1]['aggregation_code'])\n",
    "set3 = set(dropout_dfs[2]['aggregation_code'])\n",
    "\n",
    "# Find the intersection of all 4 sets - i.e., the common IDs\n",
    "common_ids = set1 & set2 & set3\n",
    "\n",
    "# Filter each DataFrame to only include rows with a common ID\n",
    "for i, df in enumerate(dropout_dfs):\n",
    "    dropout_dfs[i] = df[df['aggregation_code'].isin(common_ids)]\n",
    "    \n",
    "###########################################################\n",
    "\n",
    "common_ids = set(df['aggregation_code'])\n",
    "\n",
    "# Initialize a list to store the updated dataframes\n",
    "updated_dfs = []\n",
    "\n",
    "# Iterate over the dropout dataframes and the years together\n",
    "for year, df in zip(years, dropout_dfs):\n",
    "    # Add a new column 'year' to the dataframe\n",
    "    df['year'] = year\n",
    "    # Append the updated dataframe to the list\n",
    "    updated_dfs.append(df)\n",
    "\n",
    "# Concatenate the updated dataframes together\n",
    "dropout_df = pd.concat(updated_dfs)\n",
    "\n",
    "# drop disttricts from the dataframe\n",
    "dropout_df = dropout_df[~dropout_df['aggregation_code'].astype(str).str.endswith('0000.0')]\n",
    "\n",
    "# Reset the index of the combined dataframe\n",
    "dropout_df = dropout_df.reset_index(drop=True)\n",
    "\n",
    "common_ids = set(dropout_df['aggregation_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check if 'comparison' year is in 'membership_desc'\n",
    "def check_year_in_desc(row):\n",
    "    return str(row['comparison']) in row['membership_desc'] and \"August\" not in row['membership_desc']\n",
    "\n",
    "dropout_df = dropout_df[dropout_df['subgroup_name'] == 'All Students']\n",
    "dropout_df['report_school_year'] = dropout_df['report_school_year'].apply(lambda x: int(str(x).split('-')[1]))\n",
    "dropout_df['report_school_year'] = dropout_df['report_school_year'].apply(lambda x: x + 2000 if x < 100 else x)\n",
    "\n",
    "# Convert the 'report_school_year' to int and subtract 4\n",
    "dropout_df['comparison'] = dropout_df['report_school_year'] - 4\n",
    "\n",
    "# Apply the function to each row of dropout_df\n",
    "dropout_df = dropout_df[dropout_df.apply(check_year_in_desc, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035d0d2",
   "metadata": {},
   "source": [
    "# Combine Main Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81073e6",
   "metadata": {},
   "source": [
    "### Remove Districts, Keep Schools Common Across Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_entity_ids = set(main_data['MAIN2019']['Annual Regents Exams']['ENTITY_CD']) \n",
    "\n",
    "for database in main_data:\n",
    "    current_data = main_data[database]['Annual Regents Exams']\n",
    "    current_data['ENTITY_CD'] = current_data['ENTITY_CD'].apply(safe_convert)\n",
    "    current_data = current_data[~current_data['ENTITY_CD'].astype(str).str.endswith('0000')]\n",
    "\n",
    "    common_entity_ids = set(current_data['ENTITY_CD']) & common_ids\n",
    "    \n",
    "for database in main_data:\n",
    "    current_data = main_data[database]['Annual Regents Exams']\n",
    "    main_data[database]['Annual Regents Exams'] = current_data[current_data['ENTITY_CD'].isin(common_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for database in main_data:\n",
    "    current_data = main_data[database]['Annual Regents Exams']\n",
    "    main_data[database] = {subject: current_data[current_data['SUBJECT'] == subject] for subject in current_data['SUBJECT'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_new = {\n",
    "    'REG_PHYS_PS':'Regents Phy Set/Physics',\n",
    "    'REG_NF_GLHIST':'Regents NF Global History',\n",
    "    'REG_COMENG':'Regents Common Core English Language Art', \n",
    "    'REG_ESCI_PS':'Regents Phy Set/Earth Sci',\n",
    "    'REG_CHEM_PS':'Regents Phy Set/Chemistry', \n",
    "    'REG_COMALG1':'Regents Common Core Algebra I', \n",
    "    'REG_COMGEOM':'Regents Common Core Geometry', \n",
    "    'REG_LENV':'Regents Living Environment',\n",
    "    'REG_USHG_RV':\"Regents US History&Gov't\"\n",
    "}\n",
    "\n",
    "new_to_old = {}\n",
    "\n",
    "for key in old_to_new:\n",
    "    new_to_old[old_to_new[key]] = key\n",
    "\n",
    "tests = (set(old_to_new[test] for test in old_to_new) \n",
    "         & set(test for test in main_data['MAIN2021']) \n",
    "         & set(test for test in main_data['MAIN2022']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0e2e7",
   "metadata": {},
   "source": [
    "### Calculate Demographic Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5856ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, database in zip(years, MAIN_NAMES):\n",
    "    current_df = None\n",
    "    current_df = (main_data[database]['Regents Common Core English Language Art'] \n",
    "                  if 'Regents Common Core English Language Art' in main_data[database]\n",
    "                else main_data[database][new_to_old['Regents Common Core English Language Art']])\n",
    "\n",
    "    # Filter the DataFrame to only include rows where SUBGROUP_NAME == 'All Students'\n",
    "    total_students_df = current_df[(current_df['SUBGROUP_NAME'] == 'All Students') & (current_df['YEAR'] == year)][['ENTITY_CD', 'TESTED', 'YEAR']]\n",
    "    print(\"checkpoint 1\")\n",
    "\n",
    "    # Merge the total students for 'All Students' back into the original DataFrame\n",
    "    current_df = pd.merge(current_df, total_students_df, on=['ENTITY_CD', 'YEAR'], how='left', suffixes=('', '_total'))\n",
    "    print(\"checkpoint 2\")\n",
    "\n",
    "    # List of subgroups of interest\n",
    "    KEPT_SUBGROUPS = ['Male', 'Female', 'White', 'Hispanic or Latino', 'Black or African American', 'Asian or Native Hawaiian/Other Pacific Islander','Economically Disadvantaged']\n",
    "\n",
    "    # List to store DataFrames\n",
    "    df_list = []\n",
    "    columns = \"ENTITY_CD  ENTITY_NAME YEAR SUBJECT TESTED TESTED_total NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\"\n",
    "    columns = columns.split()\n",
    "\n",
    "    # Get ENTITY_NAME for 'All Students' subgroup\n",
    "    multiple_df = current_df[current_df['SUBGROUP_NAME'] == 'All Students'][columns]\n",
    "    print(\"checkpoint 3\")\n",
    "\n",
    "    # Loop over each subgroup and calculate percentage\n",
    "    for subgroup in KEPT_SUBGROUPS:\n",
    "        temp_df = current_df[(current_df['SUBGROUP_NAME'] == subgroup) & (current_df['YEAR'] == year)].copy()\n",
    "        subgroup = subgroup.upper()\n",
    "        temp_df[subgroup + '_PCT'] = temp_df['TESTED'] / temp_df['TESTED_total'] * 100\n",
    "        temp_df = temp_df[['ENTITY_CD', subgroup + '_PCT']]  # Keep 'ENTITY_CD' in each temp_df\n",
    "        df_list.append(temp_df)\n",
    "    print(\"checkpoint 4\")\n",
    "\n",
    "    # Merge all DataFrames on ENTITY_CD\n",
    "    result_df = multiple_df\n",
    "    for temp_df in df_list:\n",
    "        result_df = result_df.merge(temp_df, on='ENTITY_CD', how='outer')\n",
    "    print(\"checkpoint 5\")\n",
    "\n",
    "\n",
    "    # Drop observations where TESTED is less than 4\n",
    "    result_df = result_df[result_df['TESTED_total'] >= 2]\n",
    "    print(\"checkpoint 6\")\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    result_df = result_df.fillna(0)\n",
    "    print(\"checkpoint 7\")\n",
    "\n",
    "    cols = \"NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\".split()\n",
    "    for col in cols:\n",
    "        result_df[col] = result_df[col].replace('s', 0)\n",
    "    print(\"checkpoint 7\")\n",
    "    if 'Regents Common Core English Language Art' in main_data[database]:\n",
    "        main_data[database]['Regents Common Core English Language Art'] = result_df  # store results in new dictionary instead of main_data\n",
    "    else:\n",
    "        main_data[database][new_to_old['Regents Common Core English Language Art']] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_df = None\n",
    "# if 'Regents Common Core English Language Art' in main_data['MAIN2021']:\n",
    "#     current_df = main_data['MAIN2021']['Regents Common Core English Language Art']\n",
    "# else:\n",
    "#     current_df = main_data['MAIN2021'][new_to_old['Regents Common Core English Language Art']]\n",
    "\n",
    "# # Filter the DataFrame to only include rows where SUBGROUP_NAME == 'All Students'\n",
    "# total_students_df = current_df[(current_df['SUBGROUP_NAME'] == 'All Students') & (current_df['YEAR'] == 2021)][['ENTITY_CD', 'TESTED', 'YEAR']]\n",
    "\n",
    "# # Merge the total students for 'All Students' back into the original DataFrame\n",
    "# current_df = pd.merge(current_df, total_students_df, on=['ENTITY_CD', 'YEAR'], how='left', suffixes=('', '_total'))\n",
    "\n",
    "# # List of subgroups of interest\n",
    "# KEPT_SUBGROUPS = ['Male', 'Female', 'White', 'Hispanic or Latino', 'Black or African American', 'Asian or Native Hawaiian/Other Pacific Islander','Economically Disadvantaged']\n",
    "\n",
    "# # List to store DataFrames\n",
    "# df_list = []\n",
    "# columns = \"ENTITY_CD  ENTITY_NAME YEAR SUBJECT TESTED TESTED_total NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\"\n",
    "# columns = columns.split()\n",
    "\n",
    "# # Get ENTITY_NAME for 'All Students' subgroup\n",
    "# multiple_df = current_df[current_df['SUBGROUP_NAME'] == 'All Students'][columns]\n",
    "\n",
    "# # Loop over each subgroup and calculate percentage\n",
    "# for subgroup in KEPT_SUBGROUPS:\n",
    "#     temp_df = current_df[(current_df['SUBGROUP_NAME'] == subgroup) & (current_df['YEAR'] == 2021)].copy()\n",
    "#     subgroup = subgroup.upper()\n",
    "#     temp_df[subgroup + '_PCT'] = temp_df['TESTED'] / temp_df['TESTED_total'] * 100\n",
    "#     temp_df = temp_df[['ENTITY_CD', subgroup + '_PCT']]  # Keep 'ENTITY_CD' in each temp_df\n",
    "#     df_list.append(temp_df)\n",
    "\n",
    "# # Merge all DataFrames on ENTITY_CD\n",
    "# result_df = multiple_df\n",
    "# for temp_df in df_list:\n",
    "#     result_df = result_df.merge(temp_df, on='ENTITY_CD', how='outer')\n",
    "    \n",
    "\n",
    "# # Drop observations where TESTED is less than 4\n",
    "# result_df = result_df[result_df['TESTED_total'] >= 2]\n",
    "\n",
    "# # Fill NaN values with 0\n",
    "# result_df = result_df.fillna(0)\n",
    "\n",
    "# cols = \"NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\".split()\n",
    "# for col in cols:\n",
    "#     result_df[col] = result_df[col].replace('s', 0)\n",
    "\n",
    "# main_data['MAIN2021']['Regents Common Core English Language Art'] = result_df  # store results in new dictionary instead of main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968b520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# current_df = None\n",
    "# if 'Regents Common Core English Language Art' in main_data['MAIN2022']:\n",
    "#     current_df = main_data['MAIN2022']['Regents Common Core English Language Art']\n",
    "# else:\n",
    "#     current_df = main_data['MAIN2022'][new_to_old['Regents Common Core English Language Art']]\n",
    "\n",
    "# # Filter the DataFrame to only include rows where SUBGROUP_NAME == 'All Students'\n",
    "# total_students_df = current_df[(current_df['SUBGROUP_NAME'] == 'All Students') & (current_df['YEAR'] == 2022)][['ENTITY_CD', 'TESTED', 'YEAR']]\n",
    "\n",
    "# # Merge the total students for 'All Students' back into the original DataFrame\n",
    "# current_df = pd.merge(current_df, total_students_df, on=['ENTITY_CD', 'YEAR'], how='left', suffixes=('', '_total'))\n",
    "\n",
    "# # List of subgroups of interest\n",
    "# KEPT_SUBGROUPS = ['Male', 'Female', 'White', 'Hispanic or Latino', 'Black or African American', 'Asian or Native Hawaiian/Other Pacific Islander','Economically Disadvantaged']\n",
    "\n",
    "# # List to store DataFrames\n",
    "# df_list = []\n",
    "# columns = \"ENTITY_CD  ENTITY_NAME YEAR SUBJECT TESTED TESTED_total NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\"\n",
    "# columns = columns.split()\n",
    "\n",
    "# # Get ENTITY_NAME for 'All Students' subgroup\n",
    "# multiple_df = current_df[current_df['SUBGROUP_NAME'] == 'All Students'][columns]\n",
    "\n",
    "# # Loop over each subgroup and calculate percentage\n",
    "# for subgroup in KEPT_SUBGROUPS:\n",
    "#     temp_df = current_df[(current_df['SUBGROUP_NAME'] == subgroup) & (current_df['YEAR'] == 2022)].copy()\n",
    "#     subgroup = subgroup.upper()\n",
    "#     temp_df[subgroup + '_PCT'] = temp_df['TESTED'] / temp_df['TESTED_total'] * 100\n",
    "#     temp_df = temp_df[['ENTITY_CD', subgroup + '_PCT']]  # Keep 'ENTITY_CD' in each temp_df\n",
    "#     df_list.append(temp_df)\n",
    "\n",
    "# # Merge all DataFrames on ENTITY_CD\n",
    "# result_df = multiple_df\n",
    "# for temp_df in df_list:\n",
    "#     result_df = result_df.merge(temp_df, on='ENTITY_CD', how='outer')\n",
    "    \n",
    "\n",
    "# # Drop observations where TESTED is less than 4\n",
    "# result_df = result_df[result_df['TESTED_total'] >= 2]\n",
    "\n",
    "# # Fill NaN values with 0\n",
    "# result_df = result_df.fillna(0)\n",
    "\n",
    "# cols = \"NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\".split()\n",
    "# for col in cols:\n",
    "#     result_df[col] = result_df[col].replace('s', 0)\n",
    "\n",
    "# main_data['MAIN2022']['Regents Common Core English Language Art'] = result_df  # store results in new dictionary instead of main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32442ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_df = None\n",
    "# if 'Regents Common Core English Language Art' in main_data['MAIN2019']:\n",
    "#     current_df = main_data['MAIN2019']['Regents Common Core English Language Art']\n",
    "# else:\n",
    "#     current_df = main_data['MAIN2019'][new_to_old['Regents Common Core English Language Art']]\n",
    "\n",
    "# # Filter the DataFrame to only include rows where SUBGROUP_NAME == 'All Students'\n",
    "# total_students_df = current_df[(current_df['SUBGROUP_NAME'] == 'All Students') & (current_df['YEAR'] == 2019)][['ENTITY_CD', 'TESTED', 'YEAR']]\n",
    "\n",
    "# # Merge the total students for 'All Students' back into the original DataFrame\n",
    "# current_df = pd.merge(current_df, total_students_df, on=['ENTITY_CD', 'YEAR'], how='left', suffixes=('', '_total'))\n",
    "\n",
    "# # List of subgroups of interest\n",
    "# KEPT_SUBGROUPS = ['Male', 'Female', 'White', 'Hispanic or Latino', 'Black or African American', 'Asian or Native Hawaiian/Other Pacific Islander','Economically Disadvantaged']\n",
    "\n",
    "# # List to store DataFrames\n",
    "# df_list = []\n",
    "# columns = \"ENTITY_CD  ENTITY_NAME YEAR SUBJECT TESTED TESTED_total NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\"\n",
    "# columns = columns.split()\n",
    "\n",
    "# # Get ENTITY_NAME for 'All Students' subgroup\n",
    "# multiple_df = current_df[current_df['SUBGROUP_NAME'] == 'All Students'][columns]\n",
    "\n",
    "# # Loop over each subgroup and calculate percentage\n",
    "# for subgroup in KEPT_SUBGROUPS:\n",
    "#     temp_df = current_df[(current_df['SUBGROUP_NAME'] == subgroup) & (current_df['YEAR'] == 2019)].copy()\n",
    "#     subgroup = subgroup.upper()\n",
    "#     temp_df[subgroup + '_PCT'] = temp_df['TESTED'] / temp_df['TESTED_total'] * 100\n",
    "#     temp_df = temp_df[['ENTITY_CD', subgroup + '_PCT']]  # Keep 'ENTITY_CD' in each temp_df\n",
    "#     df_list.append(temp_df)\n",
    "\n",
    "# # Merge all DataFrames on ENTITY_CD\n",
    "# result_df = multiple_df\n",
    "# for temp_df in df_list:\n",
    "#     result_df = result_df.merge(temp_df, on='ENTITY_CD', how='outer')\n",
    "    \n",
    "\n",
    "# # Drop observations where TESTED is less than 4\n",
    "# result_df = result_df[result_df['TESTED_total'] >= 2]\n",
    "\n",
    "# # Fill NaN values with 0\n",
    "# result_df = result_df.fillna(0)\n",
    "\n",
    "# cols = \"NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF PER_PROF\".split()\n",
    "# for col in cols:\n",
    "#     result_df[col] = result_df[col].replace('s', 0)\n",
    "\n",
    "# main_data['MAIN2019'][new_to_old['Regents Common Core English Language Art']] = result_df  # store results in new dictionary instead of main_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37693e48",
   "metadata": {},
   "source": [
    "### Concatenate All Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc95651",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([main_data['MAIN2019'][new_to_old['Regents Common Core English Language Art']], main_data['MAIN2021']['Regents Common Core English Language Art'], main_data['MAIN2022']['Regents Common Core English Language Art']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b6706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data['SUBJECT'] = 'Regents Common Core English Language Art'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2a22d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert 'YEAR' in final_data to int\n",
    "final_data['YEAR'] = final_data['YEAR'].astype(int)\n",
    "\n",
    "# Select specific columns from dropout_df\n",
    "dropout_subset = dropout_df[['aggregation_code', 'report_school_year', 'dropout_pct']]\n",
    "\n",
    "# Merge dropout_df with final_data\n",
    "final_data = pd.merge(final_data, dropout_subset, left_on=['ENTITY_CD', 'YEAR'], right_on=['aggregation_code', 'report_school_year'], how='left')\n",
    "\n",
    "# Replace '-' with np.nan\n",
    "final_data['dropout_pct'] = final_data['dropout_pct'].replace('-', np.nan)\n",
    "\n",
    "# Remove '%' from 'dropout_pct' and convert to float\n",
    "final_data['dropout_pct'] = final_data['dropout_pct'].str.rstrip('%').astype('float')\n",
    "\n",
    "final_data['dropout_pct'] = final_data['dropout_pct'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3135450",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66071e03",
   "metadata": {},
   "source": [
    "# Import Virtual Mode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b024f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "virtual = pd.read_csv(\"../data/New_York_Schools_LearningModelData_Final.csv\", thousands=',')\n",
    "virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual = virtual[virtual['TimePeriodStart'].str.endswith(('21', '22'))]\n",
    "virtual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e880c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date columns to datetime format.\n",
    "virtual['TimePeriodStart'] = pd.to_datetime(virtual['TimePeriodStart'])\n",
    "virtual['TimePeriodEnd'] = pd.to_datetime(virtual['TimePeriodEnd'])\n",
    "\n",
    "# Create a new column for year\n",
    "virtual['YEAR'] = virtual['TimePeriodStart'].dt.year\n",
    "\n",
    "# Fill in any missing values in LearningModel with 'InPerson'\n",
    "virtual['LearningModel'] = virtual['LearningModel'].fillna('InPerson')\n",
    "\n",
    "# Replace 'In-person' with 'InPerson'\n",
    "virtual['LearningModel'] = virtual['LearningModel'].replace('In-person', 'InPerson')\n",
    "\n",
    "# Calculate the number of days for each row\n",
    "virtual['Days'] = (virtual['TimePeriodEnd'] - virtual['TimePeriodStart']).dt.days\n",
    "\n",
    "# Group by School, Year, and LearningModel and sum the number of days\n",
    "grouped = virtual.groupby(['StateAssignedSchoolID', 'YEAR', 'LearningModel'])['Days'].sum().reset_index()\n",
    "\n",
    "# Pivot the data so we have separate columns for each learning model\n",
    "pivot = grouped.pivot_table(index=['StateAssignedSchoolID', 'YEAR'], columns='LearningModel', values='Days', fill_value=0)\n",
    "\n",
    "# Reset the index\n",
    "pivot.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the total days in each year\n",
    "pivot['TotalDays'] = pivot['Virtual'] + pivot['Hybrid'] + pivot['InPerson']\n",
    "\n",
    "# Calculate the percentage of days that are virtual and hybrid for each year\n",
    "pivot['VirtualPercent'] = pivot['Virtual'] / pivot['TotalDays']\n",
    "pivot['HybridPercent'] = pivot['Hybrid'] / pivot['TotalDays']\n",
    "\n",
    "# Calculate the score for each year\n",
    "pivot['Score'] = (pivot['Virtual'] + 0.5 * pivot['Hybrid']) / pivot['TotalDays']\n",
    "\n",
    "# Reset the column names after pivot\n",
    "pivot.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf364cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot = pivot.drop(columns=['InPerson', 'Hybrid', 'Virtual', 'TotalDays'])\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dropout_df with final_data\n",
    "final_data = pd.merge(final_data, pivot, left_on=['ENTITY_CD', 'YEAR'], right_on=['StateAssignedSchoolID', 'YEAR'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop(columns=[col for col in \"ENTITY_NAME TESTED_total NUM_LEVEL1 PER_LEVEL1 NUM_LEVEL2 PER_LEVEL2 NUM_LEVEL3 PER_LEVEL3 NUM_LEVEL4 PER_LEVEL4 NUM_LEVEL5 PER_LEVEL5 NUM_PROF aggregation_code report_school_year StateAssignedSchoolID\".split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4191fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename multiple columns\n",
    "final_data = final_data.rename(columns={'ENTITY_CD': 'schoolcode', \n",
    "                        'TESTED': 'totalenroll', \n",
    "                        'PER_PROF': 'pass', \n",
    "                        'MALE_PCT': 'maleenroll',\n",
    "                        'FEMALE_PCT': 'femaleenroll',\n",
    "                        'WHITE_PCT': 'whiteenroll',\n",
    "                        'HISPANIC OR LATINO_PCT': 'hispanicenroll',     \n",
    "                        'BLACK OR AFRICAN AMERICAN_PCT': 'blackenroll',         \n",
    "                        'ASIAN OR NATIVE HAWAIIAN/OTHER PACIFIC ISLANDER_PCT': 'asianenroll',                     \n",
    "                        'ECONOMICALLY DISADVANTAGED_PCT': 'lowincomeenroll',                     \n",
    "                        'dropout_pct': 'dropout',                     \n",
    "                        'VirtualPercent': 'virtual_per',    \n",
    "                        'HybridPercent': 'hybrid_per',    \n",
    "                        'Score': 'schoolmode',    \n",
    "                        'YEAR': 'year',    \n",
    "                        'SUBJECT': 'subject',    \n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify 'schoolcode' values of rows in 2021 where 'schoolmode' is NaN\n",
    "schoolcodes_to_remove = final_data.loc[(final_data['year'] == 2021) & (final_data['schoolmode'].isna()), 'schoolcode'].unique()\n",
    "\n",
    "# Remove all rows with those 'schoolcode' values\n",
    "final_data = final_data.loc[~final_data['schoolcode'].isin(schoolcodes_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5827fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.fillna(0)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df1820",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_export = final_data[final_data[\"year\"] != 2022]\n",
    "\n",
    "first_export.to_csv(\"./clean_data/school_data_new_york.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c42429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data.to_csv(\"for_running.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
