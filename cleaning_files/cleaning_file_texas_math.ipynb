{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dat_to_csv_converter(dat_file_path):\n",
    "    # Step 1: Read the .dat file using pandas\n",
    "    # Assume .dat file is comma seperated\n",
    "    try:\n",
    "        data = pd.read_csv(dat_file_path, delimiter=',')\n",
    "        csv_file_path = dat_file_path[:-4] + \".csv\"\n",
    "        # Step 3: Write the data to a .csv file\n",
    "        data.to_csv(csv_file_path, index=False)  # Set index=False to omit row indices in the CSV\n",
    "        return csv_file_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "base_file_path = '/Users/natantes/Downloads/'\n",
    "\n",
    "final_dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "'schoolcode',\n",
    " 'year',\n",
    " 'charter',\n",
    " 'mathpass',\n",
    " 'schoolmode',\n",
    " 'virtualper',\n",
    " 'hybridper',\n",
    " 'totaltested',\n",
    " 'lowincome',\n",
    " 'white',\n",
    " 'black',\n",
    " 'hispanic',\n",
    " 'asian',\n",
    "      ]\n",
    "\n",
    "def final_data_generator(csv_file_path, year):\n",
    "    raw_dataframe = pd.read_csv(csv_file_path)\n",
    "\n",
    "    working_dataframe = raw_dataframe.copy()\n",
    "    working_dataframe['year'] = year\n",
    "    # working_dataframe['schoolcode'] = working_dataframe['CAMPUS']\n",
    "    # working_dataframe['district'] = working_dataframe['DISTRICT']\n",
    "    working_dataframe['totaltested'] = working_dataframe['a1_all_d'] \n",
    "    working_dataframe['asian'] = working_dataframe['a1_etha_d']\n",
    "    working_dataframe['black'] = working_dataframe['a1_ethb_d']\n",
    "    working_dataframe['white'] = working_dataframe['a1_ethw_d']\n",
    "    working_dataframe['hispanic'] = working_dataframe['a1_ethh_d']\n",
    "    working_dataframe['lowincome'] = working_dataframe['a1_eco2_d'] + working_dataframe['a1_eco1_d']\n",
    "    # working_dataframe['mathpass'] = working_dataframe['a1_all_meetsgl_nm']\n",
    "\n",
    "    working_dataframe['asian'] /= working_dataframe['totaltested']\n",
    "    working_dataframe['black'] /= working_dataframe['totaltested']\n",
    "    working_dataframe['white'] /= working_dataframe['totaltested']\n",
    "    working_dataframe['hispanic'] /= working_dataframe['totaltested']\n",
    "\n",
    "    final_dataframe = working_dataframe\n",
    "\n",
    "    print(f\"Year {year} is done\")\n",
    "\n",
    "    return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year $2015 is done\n",
      "Year $2016 is done\n",
      "Year $2017 is done\n",
      "Year $2018 is done\n",
      "Year $2019 is done\n",
      "[Errno 2] No such file or directory: '/Users/natantes/Downloads/texas_math_2020.dat'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     current_file_path \u001b[39m=\u001b[39m base_file_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtexas_math_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(year) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.dat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     final_csv_path \u001b[39m=\u001b[39m dat_to_csv_converter(current_file_path)\n\u001b[0;32m----> 5\u001b[0m     final_dataframes\u001b[39m.\u001b[39mappend(final_data_generator(final_csv_path, year))\n\u001b[1;32m      7\u001b[0m final_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(final_dataframes)\n\u001b[1;32m      8\u001b[0m final_dataframe\u001b[39m.\u001b[39mhead(\u001b[39m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mfinal_data_generator\u001b[0;34m(csv_file_path, year)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfinal_data_generator\u001b[39m(csv_file_path, year):\n\u001b[0;32m---> 18\u001b[0m     raw_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv_file_path)\n\u001b[1;32m     20\u001b[0m     working_dataframe \u001b[39m=\u001b[39m raw_dataframe\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     21\u001b[0m     working_dataframe[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m year\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    719\u001b[0m     path_or_buf,\n\u001b[1;32m    720\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    721\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    722\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    723\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:460\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    457\u001b[0m     \u001b[39mhasattr\u001b[39m(filepath_or_buffer, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(filepath_or_buffer, \u001b[39m\"\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    458\u001b[0m ):\n\u001b[1;32m    459\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid file path or buffer object type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(filepath_or_buffer)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    462\u001b[0m \u001b[39mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    463\u001b[0m     filepath_or_buffer\u001b[39m=\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    464\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    468\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# generate csv data from dat files\n",
    "for year in range(2015, 2023):\n",
    "    if year == 2020: continue\n",
    "    current_file_path = base_file_path + \"texas_math_\" + str(year) + \".dat\"\n",
    "    final_csv_path = dat_to_csv_converter(current_file_path)\n",
    "    final_dataframes.append(final_data_generator(final_csv_path, year))\n",
    "\n",
    "final_dataframe = pd.concat(final_dataframes)\n",
    "final_dataframe.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
